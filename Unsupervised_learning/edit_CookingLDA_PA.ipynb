{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment: \n",
    "## Готовим LDA по рецептам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы уже знаете, в тематическом моделировании делается предположение о том, что для определения тематики порядок слов в документе не важен; об этом гласит гипотеза «мешка слов». Сегодня мы будем работать с несколько нестандартной для тематического моделирования коллекцией, которую можно назвать «мешком ингредиентов», потому что на состоит из рецептов блюд разных кухонь. Тематические модели ищут слова, которые часто вместе встречаются в документах, и составляют из них темы. Мы попробуем применить эту идею к рецептам и найти кулинарные «темы». Эта коллекция хороша тем, что не требует предобработки. Кроме того, эта задача достаточно наглядно иллюстрирует принцип работы тематических моделей.\n",
    "\n",
    "Для выполнения заданий, помимо часто используемых в курсе библиотек, потребуются модули *json* и *gensim*. Первый входит в дистрибутив Anaconda, второй можно поставить командой \n",
    "\n",
    "*pip install gensim*\n",
    "\n",
    "Построение модели занимает некоторое время. На ноутбуке с процессором Intel Core i7 и тактовой частотой 2400 МГц на построение одной модели уходит менее 10 минут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коллекция дана в json-формате: для каждого рецепта известны его id, кухня (cuisine) и список ингредиентов, в него входящих. Загрузить данные можно с помощью модуля json (он входит в дистрибутив Anaconda):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "print (gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"recipes.json\") as f:\n",
    "    recipes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'cuisine': u'greek', u'id': 10259, u'ingredients': [u'romaine lettuce', u'black olives', u'grape tomatoes', u'garlic', u'pepper', u'purple onion', u'seasoning', u'garbanzo beans', u'feta cheese crumbles']}\n"
     ]
    }
   ],
   "source": [
    "print recipes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Составление корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print (gensim.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша коллекция небольшая, и целиком помещается в оперативную память. Gensim может работать с такими данными и не требует их сохранения на диск в специальном формате. Для этого коллекция должна быть представлена в виде списка списков, каждый внутренний список соответствует отдельному документу и состоит из его слов. Пример коллекции из двух документов: \n",
    "\n",
    "[[\"hello\", \"world\"], [\"programming\", \"in\", \"python\"]]\n",
    "\n",
    "Преобразуем наши данные в такой формат, а затем создадим объекты corpus и dictionary, с которыми будет работать модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [recipe[\"ingredients\"] for recipe in recipes]\n",
    "dictionary = corpora.Dictionary(texts)   # составляем словарь\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]  # составляем корпус документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'romaine lettuce', u'black olives', u'grape tomatoes', u'garlic', u'pepper', u'purple onion', u'seasoning', u'garbanzo beans', u'feta cheese crumbles']\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]\n"
     ]
    }
   ],
   "source": [
    "print texts[0]\n",
    "print corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У объекта dictionary есть полезная переменная dictionary.token2id, позволяющая находить соответствие между ингредиентами и их индексами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели\n",
    "Вам может понадобиться [документация](https://radimrehurek.com/gensim/models/ldamodel.html) LDA в gensim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1.__ Обучите модель LDA с 40 темами, установив количество проходов по коллекции 5 и оставив остальные параметры по умолчанию. \n",
    "\n",
    "\n",
    "Затем вызовите метод модели *show_topics*, указав количество тем 40 и количество токенов 10, и сохраните результат (топы ингредиентов в темах) в отдельную переменную. Если при вызове метода *show_topics* указать параметр *formatted=True*, то топы ингредиентов будет удобно выводить на печать, если *formatted=False*, будет удобно работать со списком программно. Выведите топы на печать, рассмотрите темы, а затем ответьте на вопрос:\n",
    "\n",
    "Сколько раз ингредиенты \"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\" встретились среди топов-10 всех 40 тем? При ответе __не нужно__ учитывать составные ингредиенты, например, \"hot water\".\n",
    "\n",
    "Передайте 6 чисел в функцию save_answers1 и загрузите сгенерированный файл в форму.\n",
    "\n",
    "У gensim нет возможности фиксировать случайное приближение через параметры метода, но библиотека использует numpy для инициализации матриц. Поэтому, по утверждению автора библиотеки, фиксировать случайное приближение нужно командой, которая написана в следующей ячейке. __Перед строкой кода с построением модели обязательно вставляйте указанную строку фиксации random.seed.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(76543)\n",
    "# здесь код для построения модели:\n",
    "model = models.ldamodel.LdaModel(corpus, id2word=dictionary,num_topics = 40, passes = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_topics = model.show_topics(num_topics = 40, num_words = 10, formatted = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'salt'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(model_topics[0][1][2][0]).encode('ascii','ignore') #первый индес от нуля до сорока\n",
    "#второй всегда равен 1\n",
    "#третий от нуля до десяти\n",
    "#четвертый всегда ноль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [(u'chopped onion', 0.101225525),\n",
       "   (u'garlic cloves', 0.08216655),\n",
       "   (u'salt', 0.059602775),\n",
       "   (u'fat free less sodium chicken broth', 0.053870883),\n",
       "   (u'sliced green onions', 0.047040988),\n",
       "   (u'water', 0.044889867),\n",
       "   (u'cooking spray', 0.04283082),\n",
       "   (u'spinach', 0.037372977),\n",
       "   (u'green beans', 0.036486592),\n",
       "   (u'ground red pepper', 0.031255808)]),\n",
       " (1,\n",
       "  [(u'corn kernels', 0.101373635),\n",
       "   (u'diced onions', 0.08622345),\n",
       "   (u'tortillas', 0.07210076),\n",
       "   (u'vegetable stock', 0.06630672),\n",
       "   (u'chopped fresh chives', 0.04960111),\n",
       "   (u'sliced black olives', 0.049213648),\n",
       "   (u'cream cheese, soften', 0.047810387),\n",
       "   (u'lard', 0.043290306),\n",
       "   (u'jack cheese', 0.034378912),\n",
       "   (u'canned black beans', 0.024256606)]),\n",
       " (2,\n",
       "  [(u'olive oil', 0.09265406),\n",
       "   (u'crushed red pepper', 0.06059201),\n",
       "   (u'fresh parsley', 0.05906201),\n",
       "   (u'garlic cloves', 0.047099657),\n",
       "   (u'fresh basil', 0.04458253),\n",
       "   (u'grated parmesan cheese', 0.040586088),\n",
       "   (u'butter', 0.03812486),\n",
       "   (u'salt', 0.03764013),\n",
       "   (u'cherry tomatoes', 0.035984963),\n",
       "   (u'low salt chicken broth', 0.03462202)]),\n",
       " (3,\n",
       "  [(u'bacon', 0.07397851),\n",
       "   (u'salt', 0.06975746),\n",
       "   (u'red pepper flakes', 0.06073039),\n",
       "   (u'onions', 0.05215469),\n",
       "   (u'garlic', 0.048968993),\n",
       "   (u'ground black pepper', 0.047487374),\n",
       "   (u'mushrooms', 0.04660167),\n",
       "   (u'chicken thighs', 0.042800456),\n",
       "   (u'pasta', 0.041855235),\n",
       "   (u'olive oil', 0.034014817)]),\n",
       " (4,\n",
       "  [(u'cooking spray', 0.09613435),\n",
       "   (u'salt', 0.06792525),\n",
       "   (u'powdered sugar', 0.06283473),\n",
       "   (u'all-purpose flour', 0.053522304),\n",
       "   (u'large egg whites', 0.050754756),\n",
       "   (u'large eggs', 0.049088623),\n",
       "   (u'sugar', 0.04697214),\n",
       "   (u'cream cheese', 0.04674771),\n",
       "   (u'yellow corn meal', 0.04518706),\n",
       "   (u'butter', 0.04236652)]),\n",
       " (5,\n",
       "  [(u'large garlic cloves', 0.09584141),\n",
       "   (u'shallots', 0.09215591),\n",
       "   (u'dry white wine', 0.076604754),\n",
       "   (u'olive oil', 0.056825954),\n",
       "   (u'finely chopped onion', 0.04626678),\n",
       "   (u'white wine vinegar', 0.032878842),\n",
       "   (u'unsalted butter', 0.032674495),\n",
       "   (u'arborio rice', 0.031519365),\n",
       "   (u'salt', 0.03006756),\n",
       "   (u'saffron threads', 0.027463496)]),\n",
       " (6,\n",
       "  [(u'dry red wine', 0.09032562),\n",
       "   (u'pork tenderloin', 0.06140623),\n",
       "   (u'reduced sodium soy sauce', 0.05494151),\n",
       "   (u'cilantro sprigs', 0.054090276),\n",
       "   (u'beef broth', 0.04463029),\n",
       "   (u'peppercorns', 0.042422462),\n",
       "   (u'cremini mushrooms', 0.037498955),\n",
       "   (u'rosemary', 0.026791451),\n",
       "   (u'frozen pastry puff sheets', 0.026192341),\n",
       "   (u'sage leaves', 0.026141346)]),\n",
       " (7,\n",
       "  [(u'soy sauce', 0.09035996),\n",
       "   (u'sesame oil', 0.051413693),\n",
       "   (u'scallions', 0.04356491),\n",
       "   (u'green onions', 0.042765915),\n",
       "   (u'rice vinegar', 0.041229736),\n",
       "   (u'sugar', 0.039239056),\n",
       "   (u'corn starch', 0.037083108),\n",
       "   (u'garlic', 0.03511501),\n",
       "   (u'vegetable oil', 0.033249363),\n",
       "   (u'fresh ginger', 0.026989022)]),\n",
       " (8,\n",
       "  [(u'garlic powder', 0.1722055),\n",
       "   (u'cayenne pepper', 0.12620686),\n",
       "   (u'onion powder', 0.0646297),\n",
       "   (u'ground black pepper', 0.04716695),\n",
       "   (u'smoked paprika', 0.042852987),\n",
       "   (u'black pepper', 0.040726002),\n",
       "   (u'salt', 0.040277336),\n",
       "   (u'pinenuts', 0.039355215),\n",
       "   (u'fresh spinach', 0.028684717),\n",
       "   (u'dried oregano', 0.024532164)]),\n",
       " (9,\n",
       "  [(u'extra-virgin olive oil', 0.11549947),\n",
       "   (u'garlic cloves', 0.066177174),\n",
       "   (u'fresh lemon juice', 0.060757037),\n",
       "   (u'salt', 0.055306084),\n",
       "   (u'ground black pepper', 0.051503513),\n",
       "   (u'olive oil', 0.051066905),\n",
       "   (u'plum tomatoes', 0.0474407),\n",
       "   (u'purple onion', 0.045317035),\n",
       "   (u'balsamic vinegar', 0.035160474),\n",
       "   (u'capers', 0.027769893)]),\n",
       " (10,\n",
       "  [(u'broccoli florets', 0.06542774),\n",
       "   (u'button mushrooms', 0.04968631),\n",
       "   (u'cr\\xe8me fra\\xeeche', 0.048623282),\n",
       "   (u'yellow squash', 0.04637594),\n",
       "   (u'radishes', 0.04567899),\n",
       "   (u'greek style plain yogurt', 0.03866636),\n",
       "   (u'pork sausages', 0.038560648),\n",
       "   (u'watercress', 0.035166994),\n",
       "   (u'quickcooking grits', 0.032960977),\n",
       "   (u'grated orange peel', 0.031018998)]),\n",
       " (11,\n",
       "  [(u'lime', 0.12950934),\n",
       "   (u'lime juice', 0.10625743),\n",
       "   (u'fresh cilantro', 0.056109432),\n",
       "   (u'chopped cilantro', 0.03434617),\n",
       "   (u'lime wedges', 0.032978326),\n",
       "   (u'purple onion', 0.03200026),\n",
       "   (u'mango', 0.03188407),\n",
       "   (u'garlic', 0.026007153),\n",
       "   (u'jalapeno chilies', 0.023102622),\n",
       "   (u'thai chile', 0.022420166)]),\n",
       " (12,\n",
       "  [(u'cheese', 0.09289429),\n",
       "   (u'ricotta cheese', 0.08990297),\n",
       "   (u'orange juice', 0.084840916),\n",
       "   (u'sliced mushrooms', 0.057260286),\n",
       "   (u'baby spinach', 0.056278624),\n",
       "   (u'vegetable oil cooking spray', 0.049983785),\n",
       "   (u'vegetable broth', 0.048679743),\n",
       "   (u'ground nutmeg', 0.04406521),\n",
       "   (u'frozen chopped spinach', 0.035795707),\n",
       "   (u'part-skim mozzarella cheese', 0.03281919)]),\n",
       " (13,\n",
       "  [(u'diced tomatoes', 0.0931268),\n",
       "   (u'onions', 0.063449316),\n",
       "   (u'dried oregano', 0.058664206),\n",
       "   (u'tomato sauce', 0.052352276),\n",
       "   (u'garlic', 0.047549617),\n",
       "   (u'tomato paste', 0.045980312),\n",
       "   (u'salt', 0.045934867),\n",
       "   (u'olive oil', 0.038528692),\n",
       "   (u'crushed tomatoes', 0.033045642),\n",
       "   (u'ground beef', 0.029483028)]),\n",
       " (14,\n",
       "  [(u'tomatoes', 0.10765266),\n",
       "   (u'salt', 0.09293943),\n",
       "   (u'red wine vinegar', 0.08156922),\n",
       "   (u'lemon juice', 0.0716205),\n",
       "   (u'olive oil', 0.07148763),\n",
       "   (u'cucumber', 0.06283533),\n",
       "   (u'pepper', 0.056511372),\n",
       "   (u'fresh oregano', 0.042262334),\n",
       "   (u'garlic', 0.036025327),\n",
       "   (u'purple onion', 0.032612104)]),\n",
       " (15,\n",
       "  [(u'lemon', 0.19505046),\n",
       "   (u'orange', 0.054062303),\n",
       "   (u'boiling water', 0.052012213),\n",
       "   (u'fine sea salt', 0.048428033),\n",
       "   (u'sugar', 0.04474389),\n",
       "   (u'cold water', 0.042021424),\n",
       "   (u'fennel seeds', 0.041034658),\n",
       "   (u'water', 0.0334708),\n",
       "   (u'almonds', 0.031126874),\n",
       "   (u'mint', 0.027488474)]),\n",
       " (16,\n",
       "  [(u'chopped cilantro fresh', 0.10045297),\n",
       "   (u'fresh lime juice', 0.07271232),\n",
       "   (u'jalapeno chilies', 0.06918414),\n",
       "   (u'white onion', 0.05047279),\n",
       "   (u'salt', 0.047348455),\n",
       "   (u'avocado', 0.04429011),\n",
       "   (u'garlic cloves', 0.037671167),\n",
       "   (u'ground cumin', 0.036281664),\n",
       "   (u'vegetable oil', 0.028693907),\n",
       "   (u'cilantro leaves', 0.026552413)]),\n",
       " (17,\n",
       "  [(u'ground ginger', 0.101925895),\n",
       "   (u'ground cinnamon', 0.0979965),\n",
       "   (u'raisins', 0.08348298),\n",
       "   (u'ground cloves', 0.07905478),\n",
       "   (u'white wine', 0.072416075),\n",
       "   (u'ground allspice', 0.06250153),\n",
       "   (u'fresh mushrooms', 0.056510594),\n",
       "   (u'lean ground beef', 0.05192063),\n",
       "   (u'dried rosemary', 0.03306529),\n",
       "   (u'iceberg lettuce', 0.030663066)]),\n",
       " (18,\n",
       "  [(u'parmesan cheese', 0.11489818),\n",
       "   (u'warm water', 0.07050219),\n",
       "   (u'salt', 0.06555497),\n",
       "   (u'dried basil', 0.05643707),\n",
       "   (u'olive oil', 0.052752573),\n",
       "   (u'grits', 0.038372315),\n",
       "   (u'kale', 0.031958323),\n",
       "   (u'plain flour', 0.030490592),\n",
       "   (u'water', 0.027921805),\n",
       "   (u'dry yeast', 0.026494429)]),\n",
       " (19,\n",
       "  [(u'unsalted butter', 0.118609935),\n",
       "   (u'all-purpose flour', 0.09663254),\n",
       "   (u'large eggs', 0.093114614),\n",
       "   (u'salt', 0.0755582),\n",
       "   (u'sugar', 0.06300518),\n",
       "   (u'whole milk', 0.039052986),\n",
       "   (u'granulated sugar', 0.038762856),\n",
       "   (u'baking powder', 0.033724),\n",
       "   (u'large egg yolks', 0.02583623),\n",
       "   (u'baking soda', 0.025322126)]),\n",
       " (20,\n",
       "  [(u'flat leaf parsley', 0.11742808),\n",
       "   (u'freshly ground pepper', 0.10063952),\n",
       "   (u'extra-virgin olive oil', 0.05864976),\n",
       "   (u'garlic cloves', 0.052697323),\n",
       "   (u'large shrimp', 0.04402991),\n",
       "   (u'olive oil', 0.041593578),\n",
       "   (u'salt', 0.041265726),\n",
       "   (u'dry bread crumbs', 0.032647397),\n",
       "   (u'ground black pepper', 0.02692962),\n",
       "   (u'kosher salt', 0.02572643)]),\n",
       " (21,\n",
       "  [(u'chicken broth', 0.14253525),\n",
       "   (u'green bell pepper', 0.06798291),\n",
       "   (u'boneless skinless chicken breast halves', 0.05794543),\n",
       "   (u'onions', 0.055474732),\n",
       "   (u'boneless skinless chicken breasts', 0.05544107),\n",
       "   (u'red bell pepper', 0.045975722),\n",
       "   (u'chicken breasts', 0.045292854),\n",
       "   (u'pepper', 0.040581215),\n",
       "   (u'butter', 0.03995671),\n",
       "   (u'salt', 0.03850808)]),\n",
       " (22,\n",
       "  [(u'grated parmesan cheese', 0.11064276),\n",
       "   (u'zucchini', 0.06342603),\n",
       "   (u'olive oil', 0.063145466),\n",
       "   (u'salt', 0.046205938),\n",
       "   (u'garlic', 0.040825907),\n",
       "   (u'mozzarella cheese', 0.03970455),\n",
       "   (u'shredded mozzarella cheese', 0.036605407),\n",
       "   (u'eggplant', 0.035857257),\n",
       "   (u'pepper', 0.033911593),\n",
       "   (u'eggs', 0.03150673)]),\n",
       " (23,\n",
       "  [(u'brown sugar', 0.07919159),\n",
       "   (u'soy sauce', 0.05050177),\n",
       "   (u'water', 0.04993245),\n",
       "   (u'salt', 0.049247433),\n",
       "   (u'white pepper', 0.04635464),\n",
       "   (u'oil', 0.044231247),\n",
       "   (u'sugar', 0.040791348),\n",
       "   (u'sauce', 0.03842243),\n",
       "   (u'garlic', 0.033911582),\n",
       "   (u'ketchup', 0.03256832)]),\n",
       " (24,\n",
       "  [(u'ground cumin', 0.07698195),\n",
       "   (u'ground coriander', 0.048792552),\n",
       "   (u'salt', 0.04759042),\n",
       "   (u'curry powder', 0.039715037),\n",
       "   (u'onions', 0.031481568),\n",
       "   (u'garlic cloves', 0.027215144),\n",
       "   (u'ground turmeric', 0.026869519),\n",
       "   (u'vegetable oil', 0.026711114),\n",
       "   (u'garlic', 0.025756694),\n",
       "   (u'fresh ginger', 0.023932785)]),\n",
       " (25,\n",
       "  [(u'hot water', 0.09193506),\n",
       "   (u'chopped garlic', 0.08537918),\n",
       "   (u'peanut oil', 0.061741922),\n",
       "   (u'rice wine', 0.06038283),\n",
       "   (u'hot red pepper flakes', 0.047137517),\n",
       "   (u'corn oil', 0.037632488),\n",
       "   (u'fontina cheese', 0.033558648),\n",
       "   (u'marsala wine', 0.03129974),\n",
       "   (u'seasoning', 0.031039353),\n",
       "   (u'garlic chili sauce', 0.030227398)]),\n",
       " (26,\n",
       "  [(u'mirin', 0.08430974),\n",
       "   (u'chickpeas', 0.07405199),\n",
       "   (u'red pepper', 0.051729623),\n",
       "   (u'mint leaves', 0.0512154),\n",
       "   (u'juice', 0.049591273),\n",
       "   (u'chopped fresh mint', 0.04847161),\n",
       "   (u'sugar', 0.042933334),\n",
       "   (u'sake', 0.037189852),\n",
       "   (u'fresh coriander', 0.034219984),\n",
       "   (u'spring onions', 0.03124819)]),\n",
       " (27,\n",
       "  [(u'heavy cream', 0.1848638),\n",
       "   (u'cheddar cheese', 0.10244261),\n",
       "   (u'grated nutmeg', 0.06657929),\n",
       "   (u'frozen peas', 0.06442053),\n",
       "   (u'bananas', 0.042861953),\n",
       "   (u'bread', 0.03679563),\n",
       "   (u'ice', 0.026117466),\n",
       "   (u'butter', 0.025462171),\n",
       "   (u'adobo sauce', 0.024104599),\n",
       "   (u'old bay seasoning', 0.023177503)]),\n",
       " (28,\n",
       "  [(u'oil', 0.11468751),\n",
       "   (u'salt', 0.0840665),\n",
       "   (u'cilantro leaves', 0.053758368),\n",
       "   (u'cumin seed', 0.050282843),\n",
       "   (u'green chilies', 0.049076423),\n",
       "   (u'onions', 0.046355948),\n",
       "   (u'ground turmeric', 0.044190492),\n",
       "   (u'water', 0.041809473),\n",
       "   (u'red chili peppers', 0.031238439),\n",
       "   (u'chili powder', 0.029927908)]),\n",
       " (29,\n",
       "  [(u'sour cream', 0.07530024),\n",
       "   (u'salsa', 0.045896843),\n",
       "   (u'flour tortillas', 0.045371998),\n",
       "   (u'chili powder', 0.04476668),\n",
       "   (u'corn tortillas', 0.041336708),\n",
       "   (u'shredded cheddar cheese', 0.040085796),\n",
       "   (u'black beans', 0.038982097),\n",
       "   (u'cilantro', 0.035080492),\n",
       "   (u'salt', 0.031262837),\n",
       "   (u'ground cumin', 0.027449964)]),\n",
       " (30,\n",
       "  [(u'sugar', 0.09297248),\n",
       "   (u'whipping cream', 0.080553606),\n",
       "   (u'egg yolks', 0.07650468),\n",
       "   (u'egg whites', 0.055609845),\n",
       "   (u'butter', 0.05151122),\n",
       "   (u'vanilla extract', 0.050643377),\n",
       "   (u'half & half', 0.0429321),\n",
       "   (u'sweetened condensed milk', 0.03696459),\n",
       "   (u'water', 0.033812936),\n",
       "   (u'strawberries', 0.031161234)]),\n",
       " (31,\n",
       "  [(u'shrimp', 0.0886616),\n",
       "   (u'medium shrimp', 0.05587099),\n",
       "   (u'celery ribs', 0.04826498),\n",
       "   (u'vegetable oil', 0.04292647),\n",
       "   (u'long-grain rice', 0.039882895),\n",
       "   (u'green onions', 0.038556818),\n",
       "   (u'hot sauce', 0.032452818),\n",
       "   (u'chopped celery', 0.032127276),\n",
       "   (u'long grain white rice', 0.031170323),\n",
       "   (u'rice noodles', 0.03091622)]),\n",
       " (32,\n",
       "  [(u'eggs', 0.11163333),\n",
       "   (u'milk', 0.10399788),\n",
       "   (u'salt', 0.09706748),\n",
       "   (u'butter', 0.072951116),\n",
       "   (u'all-purpose flour', 0.06668329),\n",
       "   (u'flour', 0.043779448),\n",
       "   (u'white sugar', 0.041618384),\n",
       "   (u'baking powder', 0.04088813),\n",
       "   (u'sugar', 0.040425964),\n",
       "   (u'water', 0.023151984)]),\n",
       " (33,\n",
       "  [(u'garam masala', 0.0591498),\n",
       "   (u'rice', 0.054684784),\n",
       "   (u'ginger', 0.05344861),\n",
       "   (u'tumeric', 0.0506539),\n",
       "   (u'salt', 0.04947563),\n",
       "   (u'coriander', 0.04799952),\n",
       "   (u'onions', 0.046312664),\n",
       "   (u'garlic', 0.036568455),\n",
       "   (u'cinnamon', 0.031557187),\n",
       "   (u'ghee', 0.029575799)]),\n",
       " (34,\n",
       "  [(u'cinnamon sticks', 0.09508649),\n",
       "   (u'clove', 0.08854588),\n",
       "   (u'black peppercorns', 0.07434991),\n",
       "   (u'chopped tomatoes', 0.04345795),\n",
       "   (u'cream', 0.043389942),\n",
       "   (u'yoghurt', 0.03634806),\n",
       "   (u'coriander seeds', 0.035518467),\n",
       "   (u'fresh dill', 0.03407564),\n",
       "   (u'saffron', 0.03260795),\n",
       "   (u'onions', 0.02749486)]),\n",
       " (35,\n",
       "  [(u'onions', 0.06320317),\n",
       "   (u'bay leaves', 0.059443492),\n",
       "   (u'celery', 0.054725174),\n",
       "   (u'dried thyme', 0.049715627),\n",
       "   (u'salt', 0.046534546),\n",
       "   (u'bay leaf', 0.04535375),\n",
       "   (u'water', 0.040910866),\n",
       "   (u'carrots', 0.040049154),\n",
       "   (u'garlic', 0.032554746),\n",
       "   (u'ground black pepper', 0.030801006)]),\n",
       " (36,\n",
       "  [(u'salt', 0.103166275),\n",
       "   (u'onions', 0.07904974),\n",
       "   (u'pepper', 0.07360288),\n",
       "   (u'paprika', 0.06599275),\n",
       "   (u'potatoes', 0.052116193),\n",
       "   (u'carrots', 0.045098856),\n",
       "   (u'garlic', 0.037076402),\n",
       "   (u'butter', 0.036164433),\n",
       "   (u'olive oil', 0.032652922),\n",
       "   (u'cabbage', 0.028842352)]),\n",
       " (37,\n",
       "  [(u'sea salt', 0.115319155),\n",
       "   (u'coarse salt', 0.06922137),\n",
       "   (u'crushed red pepper flakes', 0.066044144),\n",
       "   (u'extra-virgin olive oil', 0.050199963),\n",
       "   (u'ground black pepper', 0.04701652),\n",
       "   (u'ground pepper', 0.04342644),\n",
       "   (u'kosher salt', 0.037254192),\n",
       "   (u'parmigiano reggiano cheese', 0.03546906),\n",
       "   (u'olive oil', 0.02914806),\n",
       "   (u'garlic cloves', 0.027544454)]),\n",
       " (38,\n",
       "  [(u'fish sauce', 0.11313152),\n",
       "   (u'coconut milk', 0.05490867),\n",
       "   (u'garlic', 0.04352192),\n",
       "   (u'shallots', 0.035026863),\n",
       "   (u'lemongrass', 0.032011073),\n",
       "   (u'vegetable oil', 0.026119273),\n",
       "   (u'sugar', 0.025650961),\n",
       "   (u'boneless chicken skinless thigh', 0.025457399),\n",
       "   (u'cooking oil', 0.025127467),\n",
       "   (u'red chili peppers', 0.024916431)]),\n",
       " (39,\n",
       "  [(u'mayonaise', 0.1545678),\n",
       "   (u'dijon mustard', 0.09610078),\n",
       "   (u'cider vinegar', 0.06998329),\n",
       "   (u'cracked black pepper', 0.069754526),\n",
       "   (u'roma tomatoes', 0.04729288),\n",
       "   (u'white rice', 0.043958675),\n",
       "   (u'lemon wedge', 0.043681137),\n",
       "   (u'romaine lettuce', 0.033091966),\n",
       "   (u'chicken wings', 0.024559557),\n",
       "   (u'green onions', 0.023588462)])]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mushrooms'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = ['salt', 'sugar', 'water', 'mushrooms', 'chicken', 'eggs']\n",
    "(products[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = [0]*6\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    for j in range(40):\n",
    "        for k in range(10):\n",
    "            if (model_topics[j][1][k][0].encode('ascii','ignore') == products[i]):\n",
    "                counts[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23, 9, 8, 1, 0, 2]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answers1(counts):\n",
    "    with open(\"cooking_LDA_pa_task1.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in counts]))\n",
    "save_answers1(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фильтрация словаря\n",
    "В топах тем гораздо чаще встречаются первые три рассмотренных ингредиента, чем последние три. При этом наличие в рецепте курицы, яиц и грибов яснее дает понять, что мы будем готовить, чем наличие соли, сахара и воды. Таким образом, даже в рецептах есть слова, часто встречающиеся в текстах и не несущие смысловой нагрузки, и поэтому их не желательно видеть в темах. Наиболее простой прием борьбы с такими фоновыми элементами — фильтрация словаря по частоте. Обычно словарь фильтруют с двух сторон: убирают очень редкие слова (в целях экономии памяти) и очень частые слова (в целях повышения интерпретируемости тем). Мы уберем только частые слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.corpora.dictionary.Dictionary"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "dictionary2 = copy.deepcopy(dictionary)\n",
    "type(dictionary2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2.__ У объекта dictionary2 есть переменная *dfs* — это словарь, ключами которого являются id токена, а элементами — число раз, сколько слово встретилось во всей коллекции. Сохраните в отдельный список ингредиенты, которые встретились в коллекции больше 4000 раз. Вызовите метод словаря *filter_tokens*, подав в качестве первого аргумента полученный список популярных ингредиентов. Вычислите две величины: dict_size_before и dict_size_after — размер словаря до и после фильтрации.\n",
    "\n",
    "Затем, используя новый словарь, создайте новый корпус документов, corpus2, по аналогии с тем, как это сделано в начале ноутбука. Вычислите две величины: corpus_size_before и corpus_size_after — суммарное количество ингредиентов в корпусе (для каждого документа вычислите число различных ингредиентов в нем и просуммируйте по всем документам) до и после фильтрации.\n",
    "\n",
    "Передайте величины dict_size_before, dict_size_after, corpus_size_before, corpus_size_after в функцию save_answers2 и загрузите сгенерированный файл в форму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5, 11, 15, 18, 20, 29, 44, 52, 59, 104, 114]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_high_freq = []\n",
    "for i in range(len(dictionary2.dfs)):\n",
    "    if dictionary2.dfs[i] > 4000:\n",
    "        list_of_high_freq.append(i)\n",
    "list_of_high_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6714 6702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gensim.corpora.dictionary.Dictionary"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_size_before = len(dictionary.dfs)\n",
    "dict_size_after = len(dictionary2.dfs) - len(list_of_high_freq)\n",
    "print dict_size_before,dict_size_after\n",
    "type(dictionary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.corpora.dictionary.Dictionary"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary2.filter_tokens(bad_ids = list_of_high_freq)\n",
    "type(dictionary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6702"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary2.dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2 = [dictionary2.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428249 343665\n"
     ]
    }
   ],
   "source": [
    "corpus_size_before = 0\n",
    "corpus_size_after = 0\n",
    "for i in range(len(texts)):\n",
    "    corpus_size_before += len(corpus[i])\n",
    "    corpus_size_after += len(corpus2[i])\n",
    "print corpus_size_before, corpus_size_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answers2(dict_size_before, dict_size_after, corpus_size_before, corpus_size_after):\n",
    "    with open(\"cooking_LDA_pa_task2.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [dict_size_before, dict_size_after, corpus_size_before, corpus_size_after]]))\n",
    "save_answers2(dict_size_before, dict_size_after, corpus_size_before, corpus_size_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение когерентностей\n",
    "__Задание 3.__ Постройте еще одну модель по корпусу corpus2 и словарю dictionary2, остальные параметры оставьте такими же, как при первом построении модели. Сохраните новую модель в другую переменную (не перезаписывайте предыдущую модель). Не забудьте про фиксирование seed!\n",
    "\n",
    "Затем воспользуйтесь методом *top_topics* модели, чтобы вычислить ее когерентность. Передайте в качестве аргумента соответствующий модели корпус. Метод вернет список кортежей (топ токенов, когерентность), отсортированных по убыванию последней. Вычислите среднюю по всем темам когерентность для каждой из двух моделей и передайте в функцию save_answers3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(76543)\n",
    "# здесь код для построения модели:\n",
    "model_2 = models.ldamodel.LdaModel(corpus2, id2word=dictionary2, num_topics = 40, passes = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_topics_2 = model_2.top_topics(corpus2, texts, dictionary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.369090531481478 -8.56306955108467\n"
     ]
    }
   ],
   "source": [
    "top_topics = model.top_topics(corpus, texts, dictionary)\n",
    "avg_coherence_2 = sum(top_topics_2[i][1] for i in range(len(top_topics_2)))/len(top_topics_2)\n",
    "avg_coherence = sum(top_topics[i][1] for i in range(len(top_topics)))/len(top_topics)\n",
    "print avg_coherence, avg_coherence_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answers3(coherence, coherence2):\n",
    "    with open(\"cooking_LDA_pa_task3.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([\"%3f\"%el for el in [coherence, coherence2]]))\n",
    "save_answers3(avg_coherence, avg_coherence_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считается, что когерентность хорошо соотносится с человеческими оценками интерпретируемости тем. Поэтому на больших текстовых коллекциях когерентность обычно повышается, если убрать фоновую лексику. Однако в нашем случае этого не произошло. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучение влияния гиперпараметра alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом разделе мы будем работать со второй моделью, то есть той, которая построена по сокращенному корпусу. \n",
    "\n",
    "Пока что мы посмотрели только на матрицу темы-слова, теперь давайте посмотрим на матрицу темы-документы. Выведите темы для нулевого (или любого другого) документа из корпуса, воспользовавшись методом *get_document_topics* второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "matrix = max(len(model_2.get_document_topics(corpus2[i])) for i in range(len(corpus2)))\n",
    "print matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12812266"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.get_document_topics(corpus2[0])[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также выведите содержимое переменной *.alpha* второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025], dtype=float32)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У вас должно получиться, что документ характеризуется небольшим числом тем. Попробуем поменять гиперпараметр alpha, задающий априорное распределение Дирихле для распределений тем в документах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 4.__ Обучите третью модель: используйте сокращенный корпус (corpus2 и dictionary2) и установите параметр __alpha=1__, passes=5. Не забудьте про фиксацию seed! Выведите темы новой модели для нулевого документа; должно получиться, что распределение над множеством тем практически равномерное. Чтобы убедиться в том, что во второй модели документы описываются гораздо более разреженными распределениями, чем в третьей, посчитайте суммарное количество элементов, __превосходящих 0.01__, в матрицах темы-документы обеих моделей. Другими словами, запросите темы  модели для каждого документа с параметром *minimum_probability=0.01* и просуммируйте число элементов в получаемых массивах. Передайте две суммы (сначала для модели с alpha по умолчанию, затем для модели в alpha=1) в функцию save_answers4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(76543)\n",
    "# здесь код для построения модели:\n",
    "model_3 = models.ldamodel.LdaModel(corpus2, id2word=dictionary2, num_topics = 40, passes = 5, alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202112\n"
     ]
    }
   ],
   "source": [
    "count_model2 = np.count_nonzero(teta > 0.01)\n",
    "print count_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1590960\n"
     ]
    }
   ],
   "source": [
    "teta_3 = np.zeros((len(corpus2), 40))\n",
    "for index, bow in enumerate(corpus2):\n",
    "    for topic, proba in model_3.get_document_topics(bow):\n",
    "        teta_3[index, topic] = proba\n",
    "count_model3 = np.count_nonzero(teta_3 > 0.01)\n",
    "print count_model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answers4(count_model2, count_model3):\n",
    "    with open(\"cooking_LDA_pa_task4.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [count_model2, count_model3]]))\n",
    "save_answers4(count_model2, count_model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, гиперпараметр __alpha__ влияет на разреженность распределений тем в документах. Аналогично гиперпараметр __eta__ влияет на разреженность распределений слов в темах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA как способ понижения размерности\n",
    "Иногда, распределения над темами, найденные с помощью LDA, добавляют в матрицу объекты-признаки как дополнительные, семантические, признаки, и это может улучшить качество решения задачи. Для простоты давайте просто обучим классификатор рецептов на кухни на признаках, полученных из LDA, и измерим точность (accuracy).\n",
    "\n",
    "__Задание 5.__ Используйте модель, построенную по сокращенной выборке с alpha по умолчанию (вторую модель). Составьте матрицу $\\Theta = p(t|d)$ вероятностей тем в документах; вы можете использовать тот же метод get_document_topics, а также вектор правильных ответов y (в том же порядке, в котором рецепты идут в переменной recipes). Создайте объект RandomForestClassifier со 100 деревьями, с помощью функции cross_val_score вычислите среднюю accuracy по трем фолдам (перемешивать данные не нужно) и передайте в функцию save_answers5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "teta = np.zeros((len(corpus2), 40))\n",
    "for index, bow in enumerate(corpus2):\n",
    "    for topic, proba in model_2.get_document_topics(bow):\n",
    "        teta[index, topic] = proba\n",
    "        \n",
    "y = [recipe['cuisine'] for recipe in recipes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vasily\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55470105 0.54853307 0.5589345 ]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "accuracy = cross_val_score(model, teta, y)\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answers5(accuracy):\n",
    "     with open(\"cooking_LDA_pa_task5.txt\", \"w\") as fout:\n",
    "        fout.write(str(accuracy))\n",
    "save_answers5(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для такого большого количества классов это неплохая точность. Вы можете попроовать обучать RandomForest на исходной матрице частот слов, имеющей значительно большую размерность, и увидеть, что accuracy увеличивается на 10–15%. Таким образом, LDA собрал не всю, но достаточно большую часть информации из выборки, в матрице низкого ранга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA — вероятностная модель\n",
    "Матричное разложение, использующееся в LDA, интерпретируется как следующий процесс генерации документов.\n",
    "\n",
    "Для документа $d$ длины $n_d$:\n",
    "1. Из априорного распределения Дирихле с параметром alpha сгенерировать распределение над множеством тем: $\\theta_d \\sim Dirichlet(\\alpha)$\n",
    "1. Для каждого слова $w = 1, \\dots, n_d$:\n",
    "    1. Сгенерировать тему из дискретного распределения $t \\sim \\theta_{d}$\n",
    "    1. Сгенерировать слово из дискретного распределения $w \\sim \\phi_{t}$.\n",
    "    \n",
    "Подробнее об этом в [Википедии](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation).\n",
    "\n",
    "В контексте нашей задачи получается, что, используя данный генеративный процесс, можно создавать новые рецепты. Вы можете передать в функцию модель и число ингредиентов и сгенерировать рецепт :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recipe(model, num_ingredients):\n",
    "    theta = np.random.dirichlet(model.alpha)\n",
    "    for i in range(num_ingredients):\n",
    "        t = np.random.choice(np.arange(model.num_topics), p=theta)\n",
    "        topic = model.show_topic(t, topn=model.num_terms)\n",
    "        topic_distr = [x[1] for x in topic]\n",
    "        terms = [x[0] for x in topic]\n",
    "        w = np.random.choice(terms, p=topic_distr)\n",
    "        print w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интерпретация построенной модели\n",
    "Вы можете рассмотреть топы ингредиентов каждой темы. Большиснтво тем сами по себе похожи на рецепты; в некоторых собираются продукты одного вида, например, свежие фрукты или разные виды сыра.\n",
    "\n",
    "Попробуем эмпирически соотнести наши темы с национальными кухнями (cuisine). Построим матрицу $A$ размера темы $x$ кухни, ее элементы $a_{tc}$ — суммы $p(t|d)$ по всем документам $d$, которые отнесены к кухне $c$. Нормируем матрицу на частоты рецептов по разным кухням, чтобы избежать дисбаланса между кухнями. Следующая функция получает на вход объект модели, объект корпуса и исходные данные и возвращает нормированную матрицу $A$. Ее удобно визуализировать с помощью seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import seaborn\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_topic_cuisine_matrix(model, corpus, recipes):\n",
    "    # составляем вектор целевых признаков\n",
    "    targets = list(set([recipe[\"cuisine\"] for recipe in recipes]))\n",
    "    # составляем матрицу\n",
    "    tc_matrix = pandas.DataFrame(data=np.zeros((model.num_topics, len(targets))), columns=targets)\n",
    "    for recipe, bow in zip(recipes, corpus):\n",
    "        recipe_topic = model.get_document_topics(bow)\n",
    "        for t, prob in recipe_topic:\n",
    "            tc_matrix[recipe[\"cuisine\"]][t] += prob\n",
    "    # нормируем матрицу\n",
    "    target_sums = pandas.DataFrame(data=np.zeros((1, len(targets))), columns=targets)\n",
    "    for recipe in recipes:\n",
    "        target_sums[recipe[\"cuisine\"]] += 1\n",
    "    return pandas.DataFrame(tc_matrix.values/target_sums.values, columns=tc_matrix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_matrix(tc_matrix):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    seaborn.heatmap(tc_matrix, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Визуализируйте матрицу\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем темнее квадрат в матрице, тем больше связь этой темы с данной кухней. Мы видим, что у нас есть темы, которые связаны с несколькими кухнями. Такие темы показывают набор ингредиентов, которые популярны в кухнях нескольких народов, то есть указывают на схожесть кухонь этих народов. Некоторые темы распределены по всем кухням равномерно, они показывают наборы продуктов, которые часто используются в кулинарии всех стран. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Жаль, что в датасете нет названий рецептов, иначе темы было бы проще интерпретировать..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заключение\n",
    "В этом задании вы построили несколько моделей LDA, посмотрели, на что влияют гиперпараметры модели и как можно использовать построенную модель. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
